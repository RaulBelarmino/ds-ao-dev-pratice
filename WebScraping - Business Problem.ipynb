{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:30:16.582119Z",
     "start_time": "2021-07-15T15:30:16.560181Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T14:27:09.086888Z",
     "start_time": "2021-07-15T14:27:08.704231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Realizando a request do site, utilizando um agent simulando um browser para evitar problemas com a requisição\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get( url, headers=headers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:43:39.148979Z",
     "start_time": "2021-07-15T15:43:38.658661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basicamente, você utiliza o request para requisitar os dados do url simulando um browser\n",
    "## E o instância o texto para o BeautifulSoup, para realizar a extração dos dados HTML\n",
    "### O parser é a forma que o BeautifulSoup vai ler os dados do HTML\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:43:49.030238Z",
     "start_time": "2021-07-15T15:43:48.972389Z"
    }
   },
   "outputs": [],
   "source": [
    "total_item = soup.find('h2', class_='load-more-heading')\n",
    "total_item = total_item.get('data-total')\n",
    "\n",
    "page_number = np.round(int(n_page)/36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:43:59.259156Z",
     "start_time": "2021-07-15T15:43:55.950397Z"
    }
   },
   "outputs": [],
   "source": [
    "url01 = url + '?sort=stock&image-size=small&image=model&offset=0&page-size=' + str(int(page_number*36))\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get( url01, headers=headers )\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:43:59.305760Z",
     "start_time": "2021-07-15T15:43:59.259156Z"
    }
   },
   "outputs": [],
   "source": [
    "# Indexar a busca na lista de produtos\n",
    "products = soup.find('ul', class_='products-listing small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:43:59.337675Z",
     "start_time": "2021-07-15T15:43:59.310761Z"
    }
   },
   "outputs": [],
   "source": [
    "product_list = products.find_all('article', class_='hm-product-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:43:59.353632Z",
     "start_time": "2021-07-15T15:43:59.341666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Id\n",
    "product_id = [p.get('data-articlecode') for p in product_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:43:59.370588Z",
     "start_time": "2021-07-15T15:43:59.356625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Product Category\n",
    "product_category = [p.get('data-category') for p in product_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:43:59.401503Z",
     "start_time": "2021-07-15T15:43:59.374576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Product Name\n",
    "product_list = products.find_all('a', class_='link')\n",
    "product_name = [p.get_text() for p in product_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:43:59.417461Z",
     "start_time": "2021-07-15T15:43:59.403499Z"
    }
   },
   "outputs": [],
   "source": [
    "# Product color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:44:00.016183Z",
     "start_time": "2021-07-15T15:44:00.012190Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Product Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:44:00.535847Z",
     "start_time": "2021-07-15T15:44:00.502937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Product Price\n",
    "product_list = products.find_all('span',class_='price regular')\n",
    "product_price = [p.get_text() for p in product_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T15:44:01.196814Z",
     "start_time": "2021-07-15T15:44:01.158914Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "data = pd.DataFrame([product_id, product_name, product_category,product_price]).T\n",
    "data.columns = ['product_id', 'product_name', 'product_category','product_price']\n",
    "\n",
    "# Scrapy date-time\n",
    "data['scrapy-datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T17:05:03.466925Z",
     "start_time": "2021-07-15T17:05:02.612639Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get color and composition one product - API request\n",
    "\n",
    "url = 'https://www2.hm.com/en_us/productpage.0985197001.html'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get( url, headers=headers )\n",
    "\n",
    "# BeautifulSoup Object\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "#=======================color name====================#\n",
    "# A primeira cor, quando esta selecionada a classe altera para active, neste sentido, criei 2 modos e coleta\n",
    "product_list = soup.find_all('a', class_='filter-option miniature active')\n",
    "color_name = [p.get('data-color') for p in product_list]\n",
    "\n",
    "product_list = soup.find_all('a', class_='filter-option miniature')\n",
    "color_name2 = [p.get('data-color') for p in product_list]\n",
    "\n",
    "color_name = color_name + color_name2\n",
    "\n",
    "# color id\n",
    "product_list = soup.find_all('a', class_='filter-option miniature active')\n",
    "color_id1 = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "product_list = soup.find_all('a', class_='filter-option miniature')\n",
    "color_id2 = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "color_id = color_id1 + color_id2\n",
    "\n",
    "df_color = pd.DataFrame([color_id, color_name]).T\n",
    "df_color.columns = ['product_id','color_name']\n",
    "\n",
    "# generate style id + color id\n",
    "df_color['style_id'] = df_color['product_id'].apply(lambda x: x[:-3])\n",
    "df_color['color_id'] = df_color['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "#======================= composition ====================#\n",
    "product_composistion_list = soup.find_all('div', class_='pdp-description-list-item')\n",
    "product_composition = [list(filter(None, p.get_text().split('\\n'))) for p in product_composistion_list]\n",
    "\n",
    "# rename dataframe\n",
    "df_composition = pd.DataFrame(product_composition).T\n",
    "df_composition.columns = df_composition.iloc[0]\n",
    "\n",
    "# drop first row\n",
    "df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "df_composition\n",
    "\n",
    "# generate style id\n",
    "df_composition['style_id'] = df_composition['Art. No.'].apply(lambda x: x[:-3])\n",
    "df_composition\n",
    "\n",
    "#======================= merge ====================#\n",
    "data_sku = pd.merge(df_color, df_composition[['style_id','Fit','Composition']], how='left', on='style_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T17:05:07.348553Z",
     "start_time": "2021-07-15T17:05:07.308551Z"
    }
   },
   "source": [
    "## Multi products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T17:12:03.943118Z",
     "start_time": "2021-07-15T17:12:03.908109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_price</th>\n",
       "      <th>scrapy-datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0985197001</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>$ 19.99</td>\n",
       "      <td>2021-07-15 12:44:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0985159001</td>\n",
       "      <td>Skinny Jeans</td>\n",
       "      <td>men_jeans_skinny</td>\n",
       "      <td>$ 19.99</td>\n",
       "      <td>2021-07-15 12:44:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0690449022</td>\n",
       "      <td>Skinny Jeans</td>\n",
       "      <td>men_jeans_ripped</td>\n",
       "      <td>$ 39.99</td>\n",
       "      <td>2021-07-15 12:44:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0427159006</td>\n",
       "      <td>Trashed Skinny Jeans</td>\n",
       "      <td>men_jeans_ripped</td>\n",
       "      <td>$ 39.99</td>\n",
       "      <td>2021-07-15 12:44:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0985197002</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>men_jeans_slim</td>\n",
       "      <td>$ 19.99</td>\n",
       "      <td>2021-07-15 12:44:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id          product_name  product_category product_price  \\\n",
       "0  0985197001            Slim Jeans    men_jeans_slim       $ 19.99   \n",
       "1  0985159001          Skinny Jeans  men_jeans_skinny       $ 19.99   \n",
       "2  0690449022          Skinny Jeans  men_jeans_ripped       $ 39.99   \n",
       "3  0427159006  Trashed Skinny Jeans  men_jeans_ripped       $ 39.99   \n",
       "4  0985197002            Slim Jeans    men_jeans_slim       $ 19.99   \n",
       "\n",
       "       scrapy-datetime  \n",
       "0  2021-07-15 12:44:01  \n",
       "1  2021-07-15 12:44:01  \n",
       "2  2021-07-15 12:44:01  \n",
       "3  2021-07-15 12:44:01  \n",
       "4  2021-07-15 12:44:01  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T17:34:19.302111Z",
     "start_time": "2021-07-15T17:33:44.972435Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "#empty dataframe\n",
    "data_details = pd.DataFrame()\n",
    "\n",
    "#unique columns for all products composition\n",
    "aux = []\n",
    "\n",
    "cols = ['Art. No.', 'Composition', 'Fit', 'More sustainable materials', 'Product safety', 'Size']\n",
    "\n",
    "df_pattern = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # Get color and composition one product - API request\n",
    "    url = 'https://www2.hm.com/en_us/productpage.'+ data.loc[i, 'product_id'] +'.html'\n",
    "    page = requests.get( url, headers=headers )\n",
    "\n",
    "    # BeautifulSoup Object\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    #=======================color name====================#\n",
    "    # A primeira cor, quando esta selecionada a classe altera para active, neste sentido, criei 2 modos e coleta\n",
    "    product_list = soup.find_all('a', class_='filter-option miniature active')\n",
    "    color_name = [p.get('data-color') for p in product_list]\n",
    "\n",
    "    product_list = soup.find_all('a', class_='filter-option miniature')\n",
    "    color_name2 = [p.get('data-color') for p in product_list]\n",
    "\n",
    "    color_name = color_name + color_name2\n",
    "\n",
    "    # color id\n",
    "    product_list = soup.find_all('a', class_='filter-option miniature active')\n",
    "    color_id1 = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "    product_list = soup.find_all('a', class_='filter-option miniature')\n",
    "    color_id2 = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "    color_id = color_id1 + color_id2\n",
    "\n",
    "    df_color = pd.DataFrame([color_id, color_name]).T\n",
    "    df_color.columns = ['product_id','color_name']\n",
    "\n",
    "    # generate style id + color id\n",
    "    df_color['style_id'] = df_color['product_id'].apply(lambda x: x[:-3])\n",
    "    df_color['color_id'] = df_color['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "    #======================= composition ====================#\n",
    "    product_composistion_list = soup.find_all('div', class_='pdp-description-list-item')\n",
    "    product_composition = [list(filter(None, p.get_text().split('\\n'))) for p in product_composistion_list]\n",
    "\n",
    "    # rename dataframe\n",
    "    df_composition = pd.DataFrame(product_composition).T\n",
    "    df_composition.columns = df_composition.iloc[0]\n",
    "\n",
    "    # drop first row\n",
    "    df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "\n",
    "    # garantee the same number of columns\n",
    "    df_compostion = pd.concat([df_pattern, df_composition], axis=0)\n",
    "    \n",
    "    # generate style id\n",
    "    df_composition['style_id'] = df_composition['Art. No.'].apply(lambda x: x[:-3])\n",
    "    \n",
    "    aux = aux + df_composition.columns.tolist()\n",
    "    \n",
    "    #======================= merge ====================#\n",
    "    data_sku = pd.merge(df_color, df_composition, how='left', on='style_id')\n",
    "    \n",
    "    # all products details\n",
    "    data_details = pd.concat([data_details, data_sku], axis=0)\n",
    "\n",
    "# join data showroom + data details\n",
    "data['style_id'] = data['product_id'].apply(lambda x: x[:-3])\n",
    "data_raw = pd.merge(data, data_details[['style_id','color_id','color_name','Fit','Composition','Product safety','Size','More sustainable materials']], how='left', on='style_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
