{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T22:36:38.459489Z",
     "start_time": "2021-07-19T22:36:34.034395Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T22:37:01.404716Z",
     "start_time": "2021-07-19T22:37:00.875984Z"
    }
   },
   "outputs": [],
   "source": [
    "# Realizando a request do site, utilizando um agent simulando um browser para evitar problemas com a requisição\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get( url, headers=headers )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T22:37:01.810451Z",
     "start_time": "2021-07-19T22:37:01.412027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basicamente, você utiliza o request para requisitar os dados do url simulando um browser\n",
    "## E o instância o texto para o BeautifulSoup, para realizar a extração dos dados HTML\n",
    "### O parser é a forma que o BeautifulSoup vai ler os dados do HTML\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T22:37:01.872948Z",
     "start_time": "2021-07-19T22:37:01.816305Z"
    }
   },
   "outputs": [],
   "source": [
    "total_item = soup.find('h2', class_='load-more-heading')\n",
    "total_item = total_item.get('data-total')\n",
    "\n",
    "page_number = np.round(int(total_item)/36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T22:37:04.738537Z",
     "start_time": "2021-07-19T22:37:02.262573Z"
    }
   },
   "outputs": [],
   "source": [
    "url01 = url + '?sort=stock&image-size=small&image=model&offset=0&page-size=' + str(int(page_number*36))\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get( url01, headers=headers )\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T22:37:04.769292Z",
     "start_time": "2021-07-19T22:37:04.740102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Indexar a busca na lista de produtos\n",
    "products = soup.find('ul', class_='products-listing small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T22:37:04.847410Z",
     "start_time": "2021-07-19T22:37:04.777105Z"
    }
   },
   "outputs": [],
   "source": [
    "product_list = products.find_all('article', class_='hm-product-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T22:37:57.562251Z",
     "start_time": "2021-07-19T22:37:57.547598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Id\n",
    "product_id = [p.get('data-articlecode') for p in product_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T22:38:07.566664Z",
     "start_time": "2021-07-19T22:38:07.556896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T21:24:31.621219Z",
     "start_time": "2021-07-18T21:24:31.605219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Product Category\n",
    "product_category = [p.get('data-category') for p in product_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T21:24:31.661218Z",
     "start_time": "2021-07-18T21:24:31.621219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Product Name\n",
    "product_list = products.find_all('a', class_='link')\n",
    "product_name = [p.get_text() for p in product_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T21:24:31.693218Z",
     "start_time": "2021-07-18T21:24:31.661218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Product Price\n",
    "product_list = products.find_all('span',class_='price regular')\n",
    "product_price = [p.get_text() for p in product_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T21:24:31.765218Z",
     "start_time": "2021-07-18T21:24:31.693218Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "data = pd.DataFrame([product_id, product_name, product_category,product_price]).T\n",
    "data.columns = ['product_id', 'product_name', 'product_category','product_price']\n",
    "\n",
    "# Scrapy date-time\n",
    "data['scrapy-datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## One product scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T19:50:03.740917Z",
     "start_time": "2021-07-16T19:50:02.525901Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get color and composition one product - API request\n",
    "\n",
    "url = 'https://www2.hm.com/en_us/productpage.0985197001.html'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get( url, headers=headers )\n",
    "\n",
    "# BeautifulSoup Object\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "#=======================color name====================#\n",
    "# A primeira cor, quando esta selecionada a classe altera para active, neste sentido, criei 2 modos e coleta\n",
    "product_list = soup.find_all('a', class_='filter-option miniature active')\n",
    "color_name = [p.get('data-color') for p in product_list]\n",
    "\n",
    "product_list = soup.find_all('a', class_='filter-option miniature')\n",
    "color_name2 = [p.get('data-color') for p in product_list]\n",
    "\n",
    "color_name = color_name + color_name2\n",
    "\n",
    "# color id\n",
    "product_list = soup.find_all('a', class_='filter-option miniature active')\n",
    "color_id1 = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "product_list = soup.find_all('a', class_='filter-option miniature')\n",
    "color_id2 = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "color_id = color_id1 + color_id2\n",
    "\n",
    "df_color = pd.DataFrame([color_id, color_name]).T\n",
    "df_color.columns = ['product_id','color_name']\n",
    "\n",
    "# generate style id + color id\n",
    "df_color['style_id'] = df_color['product_id'].apply(lambda x: x[:-3])\n",
    "df_color['color_id'] = df_color['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "#======================= composition ====================#\n",
    "product_composistion_list = soup.find_all('div', class_='pdp-description-list-item')\n",
    "product_composition = [list(filter(None, p.get_text().split('\\n'))) for p in product_composistion_list]\n",
    "\n",
    "# rename dataframe\n",
    "df_composition = pd.DataFrame(product_composition).T\n",
    "df_composition.columns = df_composition.iloc[0]\n",
    "\n",
    "# drop first row\n",
    "df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "df_composition\n",
    "\n",
    "# generate style id\n",
    "df_composition['style_id'] = df_composition['Art. No.'].apply(lambda x: x[:-3])\n",
    "df_composition\n",
    "\n",
    "#======================= merge ====================#\n",
    "data_sku = pd.merge(df_color, df_composition[['style_id','Fit','Composition']], how='left', on='style_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T17:05:07.348553Z",
     "start_time": "2021-07-15T17:05:07.308551Z"
    }
   },
   "source": [
    "## Multi products scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-18T21:29:29.597836Z",
     "start_time": "2021-07-18T21:28:48.532218Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "#empty dataframe\n",
    "data_details = pd.DataFrame()\n",
    "\n",
    "#unique columns for all products composition\n",
    "aux = []\n",
    "\n",
    "cols = ['Art. No.', 'Composition', 'Fit', 'Product safety', 'Size']\n",
    "\n",
    "df_pattern = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    # Get color and composition one product - API request\n",
    "    url = 'https://www2.hm.com/en_us/productpage.'+ data.loc[i, 'product_id'] +'.html'\n",
    "    page = requests.get( url, headers=headers )\n",
    "\n",
    "    # BeautifulSoup Object\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    #=======================color name====================#\n",
    "    # A primeira cor, quando esta selecionada a classe altera para active, neste sentido, criei 2 modos e coleta\n",
    "    product_list = soup.find_all('a', class_=['filter-option miniature active','filter-option miniature'])\n",
    "    color_name = [p.get('data-color') for p in product_list]\n",
    "\n",
    "    # color id\n",
    "    product_list = soup.find_all('a', class_=['filter-option miniature active','filter-option miniature'])\n",
    "    color_id = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "    df_color = pd.DataFrame([color_id, color_name]).T\n",
    "    df_color.columns = ['product_id','color_name']\n",
    "\n",
    "    # generate style id + color id\n",
    "    df_color['style_id'] = df_color['product_id'].apply(lambda x: x[:-3])\n",
    "    df_color['color_id'] = df_color['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "    #======================= composition ====================#\n",
    "    product_composistion_list = soup.find_all('div', class_='pdp-description-list-item')\n",
    "    product_composition = [list(filter(None, p.get_text().split('\\n'))) for p in product_composistion_list]\n",
    "\n",
    "    # rename dataframe\n",
    "    df_composition = pd.DataFrame(product_composition).T\n",
    "    df_composition.columns = df_composition.iloc[0]\n",
    "\n",
    "    # drop first row\n",
    "    df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "\n",
    "    # garantee the same number of columns\n",
    "    df_compostion = pd.concat([df_pattern, df_composition], axis=0)\n",
    "    \n",
    "    # generate style id\n",
    "    df_composition['style_id'] = df_composition['Art. No.'].apply(lambda x: x[:-3])\n",
    "    \n",
    "    aux = aux + df_composition.columns.tolist()\n",
    "    \n",
    "    #======================= merge ====================#\n",
    "    data_sku = pd.merge(df_color, df_composition, how='left', on='style_id')\n",
    "    \n",
    "    # all products details\n",
    "    data_details = pd.concat([data_details, data_sku], axis=0)\n",
    "\n",
    "# join data showroom + data details\n",
    "data['style_id'] = data['product_id'].apply(lambda x: x[:-3])\n",
    "data_raw = pd.merge(data, data_details[['style_id','color_id','color_name','Fit','Composition','Product safety','Size']], how='left', on='style_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T17:39:44.443387Z",
     "start_time": "2021-07-19T17:39:44.424833Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_raw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-313-ba2d382679ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data-raw.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data_raw' is not defined"
     ]
    }
   ],
   "source": [
    "data_raw.to_csv('data-raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T22:54:40.072968Z",
     "start_time": "2021-07-19T22:54:39.813210Z"
    }
   },
   "outputs": [],
   "source": [
    "#===================== Clean Data =====================# \n",
    "\n",
    "data = pd.read_csv('data-raw.csv')\n",
    "\n",
    "# data clean\n",
    "df = data.copy()\n",
    "df.columns = [item.lower() for item in df.columns]\n",
    "\n",
    "#product_id\n",
    "#product_name\n",
    "df['product_name'] = df['product_name'].apply(lambda x: x.replace(' ', '_').lower())\n",
    "\n",
    "#product_category\n",
    "df['product_category'] = df['product_category'].fillna('no_category') \n",
    "\n",
    "#product_price\n",
    "df['product_price'] = df['product_price'].apply(lambda x: x.replace('$ ','')).astype(float)\n",
    "\n",
    "#scrapy-datetime\n",
    "#style_id\n",
    "#color_id\n",
    "#color_name\n",
    "df['color_name'] = df['color_name'].apply(lambda x: x.replace(' ', '_').lower())\n",
    "\n",
    "#Fit\n",
    "df['fit'] = df['fit'].apply(lambda x: x.replace(' ', '_').lower())\n",
    "\n",
    "#Size\n",
    "df['size_number'] = df['size'].apply(lambda x: re.search('\\d{3}cm', x).group(0) if pd.notnull(x) else x)\n",
    "df['size_number'] = df['size_number'].apply(lambda x: re.search('\\d{3}', x).group(0) if pd.notnull(x) else x)\n",
    "\n",
    "df['size_model'] = df['size'].str.extract('(\\d+/\\\\d+)')\n",
    "\n",
    "#Composition\n",
    "df = df[~df['composition'].str.contains('Pocket lining:', na=False)]\n",
    "df = df[~df['composition'].str.contains('Lining:', na=False)]\n",
    "df = df[~df['composition'].str.contains('Shell:', na=False)]\n",
    "\n",
    "#Product safety\n",
    "df = df.drop(columns=['product safety','size'], axis=1)\n",
    "\n",
    "#============= Break Composition Comma ==================#\n",
    "\n",
    "df1 = df['composition'].str.split(',', expand=True)\n",
    "df_ref = pd.DataFrame(index=np.arange(len(df)), columns=['cotton', 'polyester', 'elastano','elasterell'] )\n",
    "\n",
    "#cotton\n",
    "df_cotton = df1[0]\n",
    "df_cotton.name = 'cotton'\n",
    "df_ref = pd.concat([df_ref, df_cotton], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "#polyester\n",
    "df_polyester = df1.loc[df1[1].str.contains('Polyester', na=True), 1]\n",
    "df_polyester.name = 'polyester'\n",
    "df_ref = pd.concat([df_ref, df_polyester], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "\n",
    "#elastano\n",
    "df_elastano = df1.loc[df1[1].str.contains('Elastane', na=True), 1]\n",
    "df_elastano.name = 'elastano'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_elastano], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "#elasterell\n",
    "df_elasterell = df1.loc[df1[1].str.contains('Elasterell', na=True), 1]\n",
    "df_elasterell.name = 'elasterell'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_elasterell], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "#final join\n",
    "df = pd.concat([df, df_ref], axis=1, join='inner')\n",
    "\n",
    "\n",
    "#format composition data\n",
    "df['cotton'] = df['cotton'].apply(lambda x: int( re.search('\\d+',x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "df['polyester'] = df['polyester'].apply(lambda x: int( re.search('\\d+',x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "df['elastano'] = df['elastano'].apply(lambda x: int( re.search('\\d+',x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "df['elasterell'] = df['elasterell'].apply(lambda x: int( re.search('\\d+',x).group(0)) / 100 if pd.notnull(x) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T23:04:44.839075Z",
     "start_time": "2021-07-19T23:04:44.829316Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['product_id', 'product_name', 'product_category', 'product_price',\n",
    "       'style_id', 'color_id', 'color_name', 'fit','composition',\n",
    "       'size_number', 'size_model', 'cotton', 'polyester',\n",
    "       'elastano', 'elasterell', 'scrapy-datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T23:04:19.901269Z",
     "start_time": "2021-07-19T23:04:19.829975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_price</th>\n",
       "      <th>style_id</th>\n",
       "      <th>color_id</th>\n",
       "      <th>color_name</th>\n",
       "      <th>fit</th>\n",
       "      <th>composition</th>\n",
       "      <th>size_number</th>\n",
       "      <th>size_model</th>\n",
       "      <th>cotton</th>\n",
       "      <th>polyester</th>\n",
       "      <th>elastano</th>\n",
       "      <th>elasterell</th>\n",
       "      <th>scrapy-datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>427159006</td>\n",
       "      <td>trashed_skinny_jeans</td>\n",
       "      <td>men_jeans_ripped</td>\n",
       "      <td>39.99</td>\n",
       "      <td>427159</td>\n",
       "      <td>1</td>\n",
       "      <td>black_denim</td>\n",
       "      <td>skinny_fit</td>\n",
       "      <td>Cotton 93%, Polyester 6%, Elastane 1%</td>\n",
       "      <td>184</td>\n",
       "      <td>31/32</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-18 18:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>427159006</td>\n",
       "      <td>trashed_skinny_jeans</td>\n",
       "      <td>men_jeans_ripped</td>\n",
       "      <td>39.99</td>\n",
       "      <td>427159</td>\n",
       "      <td>2</td>\n",
       "      <td>blue_washed_out</td>\n",
       "      <td>skinny_fit</td>\n",
       "      <td>Cotton 93%, Polyester 6%, Elastane 1%</td>\n",
       "      <td>184</td>\n",
       "      <td>31/32</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-18 18:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>427159006</td>\n",
       "      <td>trashed_skinny_jeans</td>\n",
       "      <td>men_jeans_ripped</td>\n",
       "      <td>39.99</td>\n",
       "      <td>427159</td>\n",
       "      <td>3</td>\n",
       "      <td>denim_blue</td>\n",
       "      <td>skinny_fit</td>\n",
       "      <td>Cotton 93%, Polyester 6%, Elastane 1%</td>\n",
       "      <td>184</td>\n",
       "      <td>31/32</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-18 18:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>427159006</td>\n",
       "      <td>trashed_skinny_jeans</td>\n",
       "      <td>men_jeans_ripped</td>\n",
       "      <td>39.99</td>\n",
       "      <td>427159</td>\n",
       "      <td>4</td>\n",
       "      <td>light_denim_blue</td>\n",
       "      <td>skinny_fit</td>\n",
       "      <td>Cotton 93%, Polyester 6%, Elastane 1%</td>\n",
       "      <td>184</td>\n",
       "      <td>31/32</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-18 18:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>427159006</td>\n",
       "      <td>trashed_skinny_jeans</td>\n",
       "      <td>men_jeans_ripped</td>\n",
       "      <td>39.99</td>\n",
       "      <td>427159</td>\n",
       "      <td>5</td>\n",
       "      <td>dark_denim_blue</td>\n",
       "      <td>skinny_fit</td>\n",
       "      <td>Cotton 93%, Polyester 6%, Elastane 1%</td>\n",
       "      <td>184</td>\n",
       "      <td>31/32</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-18 18:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023</th>\n",
       "      <td>730863040</td>\n",
       "      <td>skinny_jeans</td>\n",
       "      <td>no_category</td>\n",
       "      <td>29.99</td>\n",
       "      <td>730863</td>\n",
       "      <td>33</td>\n",
       "      <td>black/no_fade_black</td>\n",
       "      <td>skinny_fit</td>\n",
       "      <td>Cotton 98%, Elastane 2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-18 18:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4024</th>\n",
       "      <td>730863040</td>\n",
       "      <td>skinny_jeans</td>\n",
       "      <td>no_category</td>\n",
       "      <td>29.99</td>\n",
       "      <td>730863</td>\n",
       "      <td>38</td>\n",
       "      <td>denim_blue</td>\n",
       "      <td>skinny_fit</td>\n",
       "      <td>Cotton 98%, Elastane 2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-18 18:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>730863040</td>\n",
       "      <td>skinny_jeans</td>\n",
       "      <td>no_category</td>\n",
       "      <td>29.99</td>\n",
       "      <td>730863</td>\n",
       "      <td>39</td>\n",
       "      <td>blue</td>\n",
       "      <td>skinny_fit</td>\n",
       "      <td>Cotton 98%, Elastane 2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-18 18:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4026</th>\n",
       "      <td>730863040</td>\n",
       "      <td>skinny_jeans</td>\n",
       "      <td>no_category</td>\n",
       "      <td>29.99</td>\n",
       "      <td>730863</td>\n",
       "      <td>40</td>\n",
       "      <td>denim_blue</td>\n",
       "      <td>skinny_fit</td>\n",
       "      <td>Cotton 98%, Elastane 2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-18 18:24:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4027</th>\n",
       "      <td>730863040</td>\n",
       "      <td>skinny_jeans</td>\n",
       "      <td>no_category</td>\n",
       "      <td>29.99</td>\n",
       "      <td>730863</td>\n",
       "      <td>43</td>\n",
       "      <td>graphite_gray</td>\n",
       "      <td>skinny_fit</td>\n",
       "      <td>Cotton 98%, Elastane 2%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-07-18 18:24:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2406 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id          product_name  product_category  product_price  \\\n",
       "82     427159006  trashed_skinny_jeans  men_jeans_ripped          39.99   \n",
       "83     427159006  trashed_skinny_jeans  men_jeans_ripped          39.99   \n",
       "84     427159006  trashed_skinny_jeans  men_jeans_ripped          39.99   \n",
       "85     427159006  trashed_skinny_jeans  men_jeans_ripped          39.99   \n",
       "86     427159006  trashed_skinny_jeans  men_jeans_ripped          39.99   \n",
       "...          ...                   ...               ...            ...   \n",
       "4023   730863040          skinny_jeans       no_category          29.99   \n",
       "4024   730863040          skinny_jeans       no_category          29.99   \n",
       "4025   730863040          skinny_jeans       no_category          29.99   \n",
       "4026   730863040          skinny_jeans       no_category          29.99   \n",
       "4027   730863040          skinny_jeans       no_category          29.99   \n",
       "\n",
       "      style_id  color_id           color_name         fit  \\\n",
       "82      427159         1          black_denim  skinny_fit   \n",
       "83      427159         2      blue_washed_out  skinny_fit   \n",
       "84      427159         3           denim_blue  skinny_fit   \n",
       "85      427159         4     light_denim_blue  skinny_fit   \n",
       "86      427159         5      dark_denim_blue  skinny_fit   \n",
       "...        ...       ...                  ...         ...   \n",
       "4023    730863        33  black/no_fade_black  skinny_fit   \n",
       "4024    730863        38           denim_blue  skinny_fit   \n",
       "4025    730863        39                 blue  skinny_fit   \n",
       "4026    730863        40           denim_blue  skinny_fit   \n",
       "4027    730863        43        graphite_gray  skinny_fit   \n",
       "\n",
       "                                composition size_number size_model  cotton  \\\n",
       "82    Cotton 93%, Polyester 6%, Elastane 1%         184      31/32    0.93   \n",
       "83    Cotton 93%, Polyester 6%, Elastane 1%         184      31/32    0.93   \n",
       "84    Cotton 93%, Polyester 6%, Elastane 1%         184      31/32    0.93   \n",
       "85    Cotton 93%, Polyester 6%, Elastane 1%         184      31/32    0.93   \n",
       "86    Cotton 93%, Polyester 6%, Elastane 1%         184      31/32    0.93   \n",
       "...                                     ...         ...        ...     ...   \n",
       "4023                Cotton 98%, Elastane 2%         NaN        NaN    0.98   \n",
       "4024                Cotton 98%, Elastane 2%         NaN        NaN    0.98   \n",
       "4025                Cotton 98%, Elastane 2%         NaN        NaN    0.98   \n",
       "4026                Cotton 98%, Elastane 2%         NaN        NaN    0.98   \n",
       "4027                Cotton 98%, Elastane 2%         NaN        NaN    0.98   \n",
       "\n",
       "      polyester  elastano  elasterell      scrapy-datetime  \n",
       "82         0.06       NaN         NaN  2021-07-18 18:24:31  \n",
       "83         0.06       NaN         NaN  2021-07-18 18:24:31  \n",
       "84         0.06       NaN         NaN  2021-07-18 18:24:31  \n",
       "85         0.06       NaN         NaN  2021-07-18 18:24:31  \n",
       "86         0.06       NaN         NaN  2021-07-18 18:24:31  \n",
       "...         ...       ...         ...                  ...  \n",
       "4023        NaN      0.02         NaN  2021-07-18 18:24:31  \n",
       "4024        NaN      0.02         NaN  2021-07-18 18:24:31  \n",
       "4025        NaN      0.02         NaN  2021-07-18 18:24:31  \n",
       "4026        NaN      0.02         NaN  2021-07-18 18:24:31  \n",
       "4027        NaN      0.02         NaN  2021-07-18 18:24:31  \n",
       "\n",
       "[2406 rows x 16 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reindex(columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
