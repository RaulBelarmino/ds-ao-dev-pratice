{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercício Prático\n",
    "**1. Coletar os seguintes dados da página: https://books.toscrape.com**\n",
    "\n",
    "**Catálogo:**\n",
    "- Classics\n",
    "\n",
    "- Science Fiction\n",
    "\n",
    "- Humor\n",
    "\n",
    "- Business\n",
    "\n",
    "**Coletar os seguintes dados de cada livro:**\n",
    "- Nome do livro\n",
    "\n",
    "- Preço em libras\n",
    "\n",
    "- Avaliação dos consumidores\n",
    "\n",
    "- Disponível em estoque\n",
    "\n",
    "**2. Faça um plano escrito para cada uma das perguntas de negócio, contendo:**\n",
    "- Saída: A simulação da tabela e gráfico final.\n",
    "\n",
    "- Processo: A sequência de passos organizada pela lógica de execução\n",
    "\n",
    "- Entrada: O link para as fontes de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planejamento para solução (SAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Saida\n",
    "**Solução resposta**\n",
    "- Coletar os dados referente a todas as categorias\n",
    "\n",
    "**Formato da entrega**\n",
    "- Tabela em formato .csv\n",
    "\n",
    "**Local da entrega**\n",
    "- Repositório Git\n",
    "\n",
    "### Processo\n",
    "\n",
    "**Construção da resposta**\n",
    "1. Realizar coleta atavés do pacote BeatifulSoup:\n",
    "2. Reconhecer a estrutura do site e html\n",
    "3. Verificar referência no html que serão válidas para todas as coletas\n",
    "4. Coletar o page size para coletar todos os dados\n",
    "5. Coletar URLs de todos os books\n",
    "6. Criar um Loop For para coletar todos os dados solicitados: Nome do livro, Preço em libras, Avaliação dos consumidores, Disponível em estoque e Categoria do livro\n",
    "7. Gerar um DataFrame dos dados coletados com Pandas\n",
    "8. Criar coluna com dia e hórario do scrapy, através do datetime.\n",
    "9. Exportar dados para .csv\n",
    "\n",
    "**Formato da Entrega**\n",
    "- Tabela, com as seguintes colunas:\n",
    "| book_name | book_category | book_price | book_rating | book_stock | book_id | scrapy_datetime |\n",
    "\n",
    "**Local de Entrega**\n",
    "- Jupyter Notebook\n",
    "\n",
    "### Entrada\n",
    "\n",
    "**Fonte de dados**\n",
    "- https://books.toscrape.com/\n",
    "\n",
    "**Ferramentas**\n",
    "- Python 3.8.5\n",
    "- BeautifulSoup\n",
    "- Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 0.0 Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:17:26.012849Z",
     "start_time": "2021-07-19T18:17:25.993324Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 1.0 Create path and headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T17:35:37.191074Z",
     "start_time": "2021-07-16T17:35:36.112762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "url = 'https://books.toscrape.com/'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "page = requests.get(url, headers=headers)\n",
    "\n",
    "# BeautifulSoup Objetct\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## 1.1 All URL Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T17:36:33.200054Z",
     "start_time": "2021-07-16T17:35:38.105676Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#================== Get all url books ====================#\n",
    "# page size\n",
    "n_page = soup.find('form', class_='form-horizontal')\n",
    "n_page = n_page.get_text().split(' ')\n",
    "n_page = n_page[0].split('\\n')[3]\n",
    "n_page = int(n_page) / 20\n",
    "page_list = list(np.arange(1, int(n_page)+1,1))\n",
    "\n",
    "list_url = []\n",
    "\n",
    "for i in range(len(page_list)):\n",
    "    url = 'https://books.toscrape.com/catalogue/page-'+ str(page_list[i]) +'.html' \n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    product_url = soup.find_all('div',class_='image_container')\n",
    "    l = [p.find('a').get('href') for p in product_url]\n",
    "    list_url = list_url + l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 2.0 Get Books Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T17:51:01.603266Z",
     "start_time": "2021-07-16T17:36:52.033638Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#================== Get books details ====================#\n",
    "#Nome do livro\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5),AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "rating_list = ['One','Two','Three','Four','Five']\n",
    "cols = ['book_name','book_category','book_price','book_rating','book_stock','book_id']\n",
    "books = pd.DataFrame(columns=cols)\n",
    "\n",
    "for i in range(len(list_url)):\n",
    "    url = 'https://books.toscrape.com/catalogue/' + list_url[i]\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    # product name\n",
    "    product_details = soup.find('div', class_='col-sm-6 product_main')\n",
    "    name = str(product_details.h1.string)\n",
    "\n",
    "    # product price\n",
    "    product_details = soup.find('p', class_='price_color')\n",
    "    price = product_details.get_text()[1:]\n",
    "\n",
    "    #product rating\n",
    "    for p in range(len(rating_list)):\n",
    "        product_details = soup.find('div', class_='col-sm-6 product_main')\n",
    "\n",
    "        if product_details.find('p', class_='star-rating '+ str(rating_list[p])):\n",
    "            aux = product_details.find('p', class_='star-rating '+ str(rating_list[p]))\n",
    "            rating = aux['class'][1]\n",
    "        else:\n",
    "            next\n",
    "\n",
    "    # product stock\n",
    "    product_details = soup.find('p', class_='instock availability')\n",
    "    stock = product_details.get_text().strip()\n",
    "    \n",
    "    # product category\n",
    "    product_details = soup.find('ul', class_='breadcrumb')\n",
    "    category = list(filter(None, product_details.get_text().split('\\n')))[2]\n",
    "    \n",
    "    # create dataframe\n",
    "    aux = pd.DataFrame([name,category,price,rating,stock]).T\n",
    "    aux.columns = ['book_name','book_category','book_price','book_rating','book_stock']\n",
    "    aux['book_id'] = i\n",
    "    \n",
    "    books = pd.concat([books, aux], axis=0)\n",
    "\n",
    "# reset index\n",
    "books = books.reset_index().drop('index',axis=1)\n",
    "\n",
    "# create datetime scrap\n",
    "\n",
    "books['scrapy-datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-16T19:30:51.313129Z",
     "start_time": "2021-07-16T19:30:50.717272Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "books.to_csv('books-list-complete.csv', index=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:48:01.749584Z",
     "start_time": "2021-07-19T18:48:01.693922Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('books-list-complete.csv')\n",
    "\n",
    "# book_name\n",
    "# book_category\n",
    "data['book_category'] = data['book_category'].apply(lambda x: x.replace(' ','_').lower() if pd.notnull(x) else x )\n",
    "\n",
    "# book_price\n",
    "data['book_price'] = data['book_price'].apply(lambda x: x.replace('£','')).astype(float)\n",
    "\n",
    "# book_rating\n",
    "data['book_rating'] = data['book_rating'].apply(lambda x: 1 if x == 'One' else\n",
    "                                                          2 if x == 'Two' else\n",
    "                                                          3 if x == 'Three' else\n",
    "                                                          4 if x == 'Four' else 5)\n",
    "\n",
    "# book_stock\n",
    "regex = '(\\d+)'\n",
    "data['book_stock'] = data['book_stock'].apply(lambda x: re.search(regex, x).group(0) if pd.notnull(x) else x)\n",
    "\n",
    "# book_id\n",
    "# scrapy-datetime\n",
    "\n",
    "# book category add_a_comment to Default\n",
    "data['book_category'] = data['book_category'].apply(lambda x: 'default' if x == 'add_a_comment' else x)\n",
    "\n",
    "# book category sorted\n",
    "data = data.sort_values('book_category', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-19T18:49:16.843280Z",
     "start_time": "2021-07-19T18:49:16.668478Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# export to csv data cleaned\n",
    "data.to_csv('books-data-clean.csv', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
